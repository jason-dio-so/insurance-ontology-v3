#!/usr/bin/env python3
"""
ë²¡í„° ì¸ë±ìŠ¤ ë¹Œë“œ ìŠ¤í¬ë¦½íŠ¸

PostgreSQLì˜ document_clause í…Œì´ë¸”ì—ì„œ ì¡°í•­ì„ ì½ì–´
ì„ë² ë”©ì„ ìƒì„±í•˜ê³  clause_embedding í…Œì´ë¸”ì— ì €ì¥í•©ë‹ˆë‹¤.

Usage:
    python vector_index/build_index.py [--backend jina|openai] [--batch-size 100]
"""

import os
import sys
import argparse
import psycopg2
from typing import List, Tuple
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# ìƒëŒ€ importê°€ ì‹¤íŒ¨í•  ê²½ìš° ì ˆëŒ€ import ì‹œë„
try:
    from .factory import get_embedder
except ImportError:
    from vector_index.factory import get_embedder


def fetch_clauses(pg_conn, limit: int = None) -> List[Tuple[int, str, dict]]:
    """
    PostgreSQLì—ì„œ ì¡°í•­ì„ ì¡°íšŒí•©ë‹ˆë‹¤.

    Args:
        pg_conn: PostgreSQL ì—°ê²°
        limit: ìµœëŒ€ ì¡°íšŒ ê°œìˆ˜ (Noneì´ë©´ ì „ì²´)

    Returns:
        (clause_id, clause_text, metadata) íŠœí”Œ ë¦¬ìŠ¤íŠ¸
    """
    with pg_conn.cursor() as cur:
        query = """
            SELECT
                dc.id,
                dc.clause_text,
                dc.clause_type,
                dc.structured_data,
                d.doc_type,
                d.product_id,
                ARRAY_AGG(cc.coverage_id) FILTER (WHERE cc.coverage_id IS NOT NULL) as coverage_ids
            FROM document_clause dc
            JOIN document d ON dc.document_id = d.id
            LEFT JOIN clause_coverage cc ON dc.id = cc.clause_id
            GROUP BY dc.id, dc.clause_text, dc.clause_type, dc.structured_data, d.doc_type, d.product_id
            ORDER BY dc.id
        """

        if limit:
            query += f" LIMIT {limit}"

        cur.execute(query)
        results = []
        for row in cur.fetchall():
            clause_id = row[0]
            clause_text = row[1]
            clause_type = row[2]
            structured_data = row[3]
            doc_type = row[4]
            product_id = row[5]
            coverage_ids = row[6] if row[6] else []

            metadata = {
                'clause_type': clause_type,
                'doc_type': doc_type,
                'product_id': product_id,
                'coverage_ids': coverage_ids
            }

            if structured_data:
                metadata['structured_data'] = structured_data

            results.append((clause_id, clause_text, metadata))

        return results


def build_embeddings(
    pg_conn,
    backend: str = "jina",
    batch_size: int = 100,
    limit: int = None
):
    """
    ì¡°í•­ ì„ë² ë”©ì„ ìƒì„±í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤.

    Args:
        pg_conn: PostgreSQL ì—°ê²°
        backend: ì„ë² ë”© ë°±ì—”ë“œ (jina ë˜ëŠ” openai)
        batch_size: ë°°ì¹˜ í¬ê¸°
        limit: ìµœëŒ€ ì²˜ë¦¬ ê°œìˆ˜ (Noneì´ë©´ ì „ì²´)
    """
    print(f"ğŸ”§ Using embedding backend: {backend}")

    # Embedder ìƒì„±
    embedder = get_embedder(backend)
    model_name = embedder.get_model_name()
    dimension = embedder.get_dimension()

    print(f"   Model: {model_name}")
    print(f"   Dimension: {dimension}")
    print()

    # ê¸°ì¡´ ì„ë² ë”© í™•ì¸ (ì‚­ì œí•˜ì§€ ì•ŠìŒ)
    print("ğŸ” Checking existing embeddings...")
    with pg_conn.cursor() as cur:
        cur.execute("SELECT COUNT(*) FROM clause_embedding")
        existing_count = cur.fetchone()[0]

        # ì´ë¯¸ ì„ë² ë”©ëœ clause_id ì¡°íšŒ
        cur.execute("SELECT clause_id FROM clause_embedding")
        existing_ids = set(row[0] for row in cur.fetchall())

    print(f"   Found {existing_count} existing embeddings")
    print(f"   Will skip {len(existing_ids)} clauses")
    print()

    # ì¡°í•­ ì¡°íšŒ
    print("ğŸ“¦ Fetching clauses from PostgreSQL...")
    clauses = fetch_clauses(pg_conn, limit=limit)

    # ì´ë¯¸ ì„ë² ë”©ëœ clause í•„í„°ë§
    clauses_to_process = [(cid, text, meta) for cid, text, meta in clauses if cid not in existing_ids]

    total_clauses = len(clauses)
    total_to_process = len(clauses_to_process)

    print(f"   Found {total_clauses} total clauses")
    print(f"   Need to process: {total_to_process} clauses")
    print(f"   Already embedded: {total_clauses - total_to_process} clauses")
    print()

    if total_to_process == 0:
        print("âœ… All clauses already embedded. Nothing to do.")
        return

    clauses = clauses_to_process
    total = total_to_process

    # ë°°ì¹˜ ì²˜ë¦¬
    print(f"ğŸ”„ Generating embeddings (batch size: {batch_size})...")
    processed = 0

    with pg_conn.cursor() as cur:
        for i in range(0, total, batch_size):
            batch_clauses = clauses[i:i + batch_size]
            clause_ids = [c[0] for c in batch_clauses]
            texts = [c[1] for c in batch_clauses]
            metadatas = [c[2] for c in batch_clauses]

            # ì„ë² ë”© ìƒì„±
            try:
                embeddings = embedder.embed_documents(texts)
            except Exception as e:
                print(f"   âŒ Error generating embeddings: {e}")
                continue

            # DBì— ì €ì¥
            for clause_id, embedding, metadata in zip(clause_ids, embeddings, metadatas):
                # pgvectorëŠ” ë¦¬ìŠ¤íŠ¸ë¥¼ ìë™ìœ¼ë¡œ ë³€í™˜
                # metadataë¥¼ JSONìœ¼ë¡œ ì €ì¥
                import json
                cur.execute("""
                    INSERT INTO clause_embedding (clause_id, embedding, model_name, metadata)
                    VALUES (%s, %s, %s, %s)
                """, (clause_id, embedding, model_name, json.dumps(metadata)))

            pg_conn.commit()

            processed += len(batch_clauses)
            print(f"   [{processed}/{total}] {processed * 100 // total}% completed")

    print()
    print("=" * 60)
    print("âœ… Index build completed!")
    print("=" * 60)
    print(f"   Total clauses: {total}")
    print(f"   Model: {model_name}")
    print(f"   Dimension: {dimension}")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description="ë²¡í„° ì¸ë±ìŠ¤ ë¹Œë“œ")
    parser.add_argument(
        "--backend",
        choices=["fastembed", "bge", "jina", "openai"],
        default=os.getenv("EMBEDDING_BACKEND", "fastembed"),
        help="ì„ë² ë”© ë°±ì—”ë“œ (ê¸°ë³¸: fastembed)"
    )
    parser.add_argument(
        "--batch-size",
        type=int,
        default=100,
        help="ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸: 100)"
    )
    parser.add_argument(
        "--limit",
        type=int,
        default=None,
        help="ìµœëŒ€ ì²˜ë¦¬ ê°œìˆ˜ (í…ŒìŠ¤íŠ¸ìš©, ê¸°ë³¸: ì „ì²´)"
    )

    args = parser.parse_args()

    print("=" * 60)
    print("ë²¡í„° ì¸ë±ìŠ¤ ë¹Œë“œ")
    print("=" * 60)
    print()

    # PostgreSQL ì—°ê²°
    postgres_url = os.getenv(
        "POSTGRES_URL",
        "postgresql://postgres:postgres@localhost:5432/insurance_ontology"
    )

    try:
        pg_conn = psycopg2.connect(postgres_url)
        print("âœ… Connected to PostgreSQL")
        print()

        build_embeddings(
            pg_conn,
            backend=args.backend,
            batch_size=args.batch_size,
            limit=args.limit
        )

        pg_conn.close()

    except Exception as e:
        print(f"âŒ Error: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
