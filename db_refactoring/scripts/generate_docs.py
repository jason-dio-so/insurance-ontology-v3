#!/usr/bin/env python3
"""
PostgreSQL ìŠ¤í‚¤ë§ˆì—ì„œ ë¬¸ì„œ ìë™ ìƒì„± ìŠ¤í¬ë¦½íŠ¸

ìƒì„± ë¬¸ì„œ:
- DATA_DICTIONARY.md: í…Œì´ë¸”ë³„ ì»¬ëŸ¼ ì •ì˜
- RELATIONSHIP_MAP.md: ì™¸ë˜í‚¤ ê´€ê³„ ë§µ

ì‚¬ìš©ë²•:
    python generate_docs.py [--db-url DATABASE_URL] [--output-dir OUTPUT_DIR]
"""

import os
import argparse
from datetime import datetime
from typing import Optional

import psycopg2
from psycopg2.extras import RealDictCursor


def get_connection(db_url: str):
    """DB ì—°ê²° ìƒì„±"""
    return psycopg2.connect(db_url, cursor_factory=RealDictCursor)


def get_tables(conn) -> list:
    """ëª¨ë“  í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ"""
    query = """
    SELECT table_name
    FROM information_schema.tables
    WHERE table_schema = 'public'
      AND table_type = 'BASE TABLE'
    ORDER BY table_name
    """
    with conn.cursor() as cur:
        cur.execute(query)
        return [row['table_name'] for row in cur.fetchall()]


def get_table_comment(conn, table_name: str) -> Optional[str]:
    """í…Œì´ë¸” ì½”ë©˜íŠ¸ ì¡°íšŒ"""
    query = """
    SELECT obj_description(c.oid) as comment
    FROM pg_class c
    JOIN pg_namespace n ON n.oid = c.relnamespace
    WHERE c.relname = %s AND n.nspname = 'public'
    """
    with conn.cursor() as cur:
        cur.execute(query, (table_name,))
        row = cur.fetchone()
        return row['comment'] if row else None


def get_columns(conn, table_name: str) -> list:
    """í…Œì´ë¸” ì»¬ëŸ¼ ì •ë³´ ì¡°íšŒ"""
    query = """
    SELECT
        c.column_name,
        c.data_type,
        c.character_maximum_length,
        c.numeric_precision,
        c.numeric_scale,
        c.is_nullable,
        c.column_default,
        pgd.description as comment
    FROM information_schema.columns c
    LEFT JOIN pg_catalog.pg_statio_all_tables st
        ON c.table_schema = st.schemaname AND c.table_name = st.relname
    LEFT JOIN pg_catalog.pg_description pgd
        ON pgd.objoid = st.relid AND pgd.objsubid = c.ordinal_position
    WHERE c.table_schema = 'public' AND c.table_name = %s
    ORDER BY c.ordinal_position
    """
    with conn.cursor() as cur:
        cur.execute(query, (table_name,))
        return cur.fetchall()


def get_primary_keys(conn, table_name: str) -> list:
    """ê¸°ë³¸í‚¤ ì»¬ëŸ¼ ì¡°íšŒ"""
    query = """
    SELECT a.attname as column_name
    FROM pg_index i
    JOIN pg_attribute a ON a.attrelid = i.indrelid AND a.attnum = ANY(i.indkey)
    JOIN pg_class c ON c.oid = i.indrelid
    JOIN pg_namespace n ON n.oid = c.relnamespace
    WHERE i.indisprimary AND c.relname = %s AND n.nspname = 'public'
    """
    with conn.cursor() as cur:
        cur.execute(query, (table_name,))
        return [row['column_name'] for row in cur.fetchall()]


def get_foreign_keys(conn) -> list:
    """ëª¨ë“  ì™¸ë˜í‚¤ ê´€ê³„ ì¡°íšŒ"""
    query = """
    SELECT
        tc.table_name as from_table,
        kcu.column_name as from_column,
        ccu.table_name as to_table,
        ccu.column_name as to_column,
        tc.constraint_name
    FROM information_schema.table_constraints tc
    JOIN information_schema.key_column_usage kcu
        ON tc.constraint_name = kcu.constraint_name
        AND tc.table_schema = kcu.table_schema
    JOIN information_schema.constraint_column_usage ccu
        ON ccu.constraint_name = tc.constraint_name
        AND ccu.table_schema = tc.table_schema
    WHERE tc.constraint_type = 'FOREIGN KEY'
        AND tc.table_schema = 'public'
    ORDER BY tc.table_name, kcu.column_name
    """
    with conn.cursor() as cur:
        cur.execute(query)
        return cur.fetchall()


def get_indexes(conn, table_name: str) -> list:
    """í…Œì´ë¸” ì¸ë±ìŠ¤ ì¡°íšŒ"""
    query = """
    SELECT
        i.relname as index_name,
        am.amname as index_type,
        array_agg(a.attname ORDER BY x.n) as columns,
        ix.indisunique as is_unique,
        ix.indisprimary as is_primary
    FROM pg_index ix
    JOIN pg_class i ON i.oid = ix.indexrelid
    JOIN pg_class t ON t.oid = ix.indrelid
    JOIN pg_namespace n ON n.oid = t.relnamespace
    JOIN pg_am am ON am.oid = i.relam
    CROSS JOIN LATERAL unnest(ix.indkey) WITH ORDINALITY AS x(attnum, n)
    JOIN pg_attribute a ON a.attrelid = t.oid AND a.attnum = x.attnum
    WHERE t.relname = %s AND n.nspname = 'public'
    GROUP BY i.relname, am.amname, ix.indisunique, ix.indisprimary
    ORDER BY i.relname
    """
    with conn.cursor() as cur:
        cur.execute(query, (table_name,))
        return cur.fetchall()


def format_data_type(col: dict) -> str:
    """ë°ì´í„° íƒ€ì… í¬ë§·íŒ…"""
    dtype = col['data_type']

    if dtype == 'character varying':
        return f"varchar({col['character_maximum_length']})"
    elif dtype == 'numeric':
        return f"numeric({col['numeric_precision']},{col['numeric_scale']})"
    elif dtype == 'USER-DEFINED':
        return 'vector'
    else:
        return dtype


def generate_data_dictionary(conn, output_dir: str):
    """DATA_DICTIONARY.md ìƒì„±"""
    tables = get_tables(conn)

    lines = [
        "# ë°ì´í„° ì‚¬ì „ (Data Dictionary)",
        "",
        f"> ìë™ ìƒì„±ì¼: {datetime.now().strftime('%Y-%m-%d %H:%M')}",
        "",
        "## ëª©ì°¨",
        "",
    ]

    # ëª©ì°¨ ìƒì„±
    for table in tables:
        comment = get_table_comment(conn, table) or ''
        lines.append(f"- [{table}](#{table}) - {comment}")

    lines.append("")
    lines.append("---")
    lines.append("")

    # ê° í…Œì´ë¸” ìƒì„¸
    for table in tables:
        comment = get_table_comment(conn, table)
        pks = get_primary_keys(conn, table)
        columns = get_columns(conn, table)
        indexes = get_indexes(conn, table)

        lines.append(f"## {table}")
        lines.append("")
        if comment:
            lines.append(f"**ì„¤ëª…**: {comment}")
            lines.append("")

        # ì»¬ëŸ¼ í…Œì´ë¸”
        lines.append("### ì»¬ëŸ¼")
        lines.append("")
        lines.append("| ì»¬ëŸ¼ëª… | íƒ€ì… | NULL | ê¸°ë³¸ê°’ | ì„¤ëª… |")
        lines.append("|--------|------|------|--------|------|")

        for col in columns:
            pk_mark = " ğŸ”‘" if col['column_name'] in pks else ""
            nullable = "N" if col['is_nullable'] == 'NO' else "Y"
            default = col['column_default'] or '-'
            if len(default) > 30:
                default = default[:27] + '...'
            col_comment = col['comment'] or '-'
            dtype = format_data_type(col)

            lines.append(f"| {col['column_name']}{pk_mark} | {dtype} | {nullable} | {default} | {col_comment} |")

        lines.append("")

        # ì¸ë±ìŠ¤
        if indexes:
            lines.append("### ì¸ë±ìŠ¤")
            lines.append("")
            lines.append("| ì¸ë±ìŠ¤ëª… | íƒ€ì… | ì»¬ëŸ¼ | ìœ ë‹ˆí¬ |")
            lines.append("|----------|------|------|--------|")
            for idx in indexes:
                if idx['is_primary']:
                    continue
                unique = "Y" if idx['is_unique'] else "N"
                cols = ', '.join(idx['columns'])
                lines.append(f"| {idx['index_name']} | {idx['index_type']} | {cols} | {unique} |")
            lines.append("")

        lines.append("---")
        lines.append("")

    # íŒŒì¼ ì €ì¥
    output_path = os.path.join(output_dir, "DATA_DICTIONARY.md")
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write('\n'.join(lines))

    print(f"âœ… ìƒì„±ë¨: {output_path}")
    return output_path


def generate_relationship_map(conn, output_dir: str):
    """RELATIONSHIP_MAP.md ìƒì„±"""
    fks = get_foreign_keys(conn)
    tables = get_tables(conn)

    lines = [
        "# í…Œì´ë¸” ê´€ê³„ ë§µ (Relationship Map)",
        "",
        f"> ìë™ ìƒì„±ì¼: {datetime.now().strftime('%Y-%m-%d %H:%M')}",
        "",
        "## ì™¸ë˜í‚¤ ê´€ê³„ ëª©ë¡",
        "",
        "| From í…Œì´ë¸” | From ì»¬ëŸ¼ | â†’ | To í…Œì´ë¸” | To ì»¬ëŸ¼ |",
        "|-------------|-----------|---|-----------|---------|",
    ]

    for fk in fks:
        lines.append(f"| {fk['from_table']} | {fk['from_column']} | â†’ | {fk['to_table']} | {fk['to_column']} |")

    lines.append("")
    lines.append("---")
    lines.append("")

    # í…Œì´ë¸”ë³„ ê´€ê³„ ìš”ì•½
    lines.append("## í…Œì´ë¸”ë³„ ê´€ê³„ ìš”ì•½")
    lines.append("")

    for table in tables:
        # ì´ í…Œì´ë¸”ì´ ì°¸ì¡°í•˜ëŠ” í…Œì´ë¸”
        refs_to = [fk for fk in fks if fk['from_table'] == table]
        # ì´ í…Œì´ë¸”ì„ ì°¸ì¡°í•˜ëŠ” í…Œì´ë¸”
        refs_from = [fk for fk in fks if fk['to_table'] == table]

        if refs_to or refs_from:
            comment = get_table_comment(conn, table) or ''
            lines.append(f"### {table}")
            if comment:
                lines.append(f"_{comment}_")
            lines.append("")

            if refs_to:
                lines.append("**ì°¸ì¡°í•˜ëŠ” í…Œì´ë¸”:**")
                for fk in refs_to:
                    lines.append(f"- `{fk['from_column']}` â†’ `{fk['to_table']}.{fk['to_column']}`")
                lines.append("")

            if refs_from:
                lines.append("**ì°¸ì¡°ë˜ëŠ” í…Œì´ë¸”:**")
                for fk in refs_from:
                    lines.append(f"- `{fk['from_table']}.{fk['from_column']}` â†’ `{fk['to_column']}`")
                lines.append("")

    # Mermaid ë‹¤ì´ì–´ê·¸ë¨
    lines.append("---")
    lines.append("")
    lines.append("## ER ë‹¤ì´ì–´ê·¸ë¨ (Mermaid)")
    lines.append("")
    lines.append("```mermaid")
    lines.append("erDiagram")

    for fk in fks:
        lines.append(f"    {fk['to_table']} ||--o{{ {fk['from_table']} : \"{fk['from_column']}\"")

    lines.append("```")
    lines.append("")

    # íŒŒì¼ ì €ì¥
    output_path = os.path.join(output_dir, "RELATIONSHIP_MAP.md")
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write('\n'.join(lines))

    print(f"âœ… ìƒì„±ë¨: {output_path}")
    return output_path


def main():
    parser = argparse.ArgumentParser(description='PostgreSQL ìŠ¤í‚¤ë§ˆ ë¬¸ì„œ ìë™ ìƒì„±')
    parser.add_argument('--db-url',
                        default=os.environ.get('DATABASE_URL',
                                               'postgresql://postgres:postgres@127.0.0.1:5432/insurance_ontology'),
                        help='PostgreSQL ì—°ê²° URL')
    parser.add_argument('--output-dir',
                        default=os.path.join(os.path.dirname(__file__), '..', 'docs'),
                        help='ì¶œë ¥ ë””ë ‰í† ë¦¬')

    args = parser.parse_args()

    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(args.output_dir, exist_ok=True)

    print(f"ğŸ“Š DB ì—°ê²°: {args.db_url.split('@')[1] if '@' in args.db_url else args.db_url}")
    print(f"ğŸ“ ì¶œë ¥ ê²½ë¡œ: {args.output_dir}")
    print()

    try:
        conn = get_connection(args.db_url)

        generate_data_dictionary(conn, args.output_dir)
        generate_relationship_map(conn, args.output_dir)

        conn.close()
        print()
        print("âœ… ë¬¸ì„œ ìƒì„± ì™„ë£Œ!")

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")
        raise


if __name__ == '__main__':
    main()
