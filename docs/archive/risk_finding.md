ë¦¬ìŠ¤í¬ 3 ë¶„ì„ ê²°ê³¼ë¥¼ ë§ˆí¬ë‹¤ìš´ ë¬¸ì„œë¡œ ì‘ì„±í•˜ê² ìŠµë‹ˆë‹¤:

  # Coverage Extraction Quality Analysis Report

  **Date**: 2025-12-10
  **Scope**: All 8 insurance carriers
  **Total Coverages Analyzed**: 357

  ## Executive Summary

  Phase 5 evaluation revealed that coverage extraction issues extend beyond Lotte (ë¡¯ë°) to **all insurance carriers**. Approximately **28-36% of 
  extracted coverages have quality issues**, ranging from category headers misidentified as coverages to numeric-only names.

  ## Problem Classification

  ### Type 1: Category Headers Extracted as Coverages

  **Affected Carriers**: ë¡¯ë° (Lotte)

  **Issue**: PDF table category headers ("ì•”ê´€ë ¨", "ë‡Œì§ˆí™˜", "ì‹¬ì¥ì§ˆí™˜") incorrectly extracted as `table_row` instead of being filtered out.

  **Examples**:
  ```json
  // Incorrect extraction
  {"coverage_name": "ì•”ê´€ë ¨", "coverage_amount": 30000000}
  {"coverage_name": "ë‡Œì§ˆí™˜", "coverage_amount": 10000000}

  // Should be
  {"coverage_name": "ì¼ë°˜ì•”ì§„ë‹¨ë¹„â…¡", "coverage_amount": 30000000}
  {"coverage_name": "ë‡Œì¶œí˜ˆì§„ë‹¨ë¹„", "coverage_amount": 10000000}

  Impact: 14/57 coverages (24.6%)

  Root Cause:
  - Lotte proposal PDFs use 2-4 character category headers
  - table_parser.py does not distinguish headers from actual coverage rows
  - Header rows typically contain general terms: "ê´€ë ¨", "ì§ˆí™˜"

  Type 2: Numeric-Only Coverage Names

  Affected Carriers: KB, ì‚¼ì„± (Samsung)

  Issue: Coverage names extracted as pure numbers or time periods.

  Examples:

  KB Insurance (33% affected):
  {"coverage_name": "10,060", ...}
  {"coverage_name": "1,435", ...}
  {"coverage_name": "22,510", ...}

  Samsung Fire (10% affected):
  {"coverage_name": "3ê°œì›”", "coverage_amount": 355038}
  {"coverage_name": "6ê°œì›”", "coverage_amount": 710076}
  {"coverage_name": "10ë…„", "coverage_amount": 14201520}

  Impact:
  - KB: 12/36 coverages
  - Samsung: 4/39 coverages

  Root Cause:
  - KB: Severe PDF parsing error - coverage name column missing (same issue as Phase 1 discovery)
  - Samsung: Time period payment schedules extracted as coverages

  Type 3: Newline Characters in Coverage Names

  Affected Carriers: ë©”ë¦¬ì¸  (Meritz)

  Issue: Coverage names contain embedded newline characters (\n).

  Examples:
  {"coverage_name": "ì§€ê¸‰\në³´í—˜ê¸ˆ", ...}
  {"coverage_name": "íŠ¹ì •\nì¹˜ë£Œ", ...}
  {"coverage_name": "ê²€\nì‚¬", ...}

  Impact: 3-4/98 coverages (3-4%)

  Root Cause: PDF parsing doesn't properly handle line breaks within table cells.

  Type 4: Generic/Ambiguous Names

  Affected Carriers: DB, í•œí™”, í˜„ëŒ€, ì‚¼ì„±, ë©”ë¦¬ì¸  (all)

  Issue: Very short, generic coverage names that lack specificity.

  Examples:
  - "ì§ˆë³‘ì‚¬ë§" (Disease Death)
  - "ìƒí•´ìˆ˜ìˆ ë¹„" (Injury Surgery Cost)
  - "í™”ìƒì§„ë‹¨ë¹„" (Burn Diagnosis)
  - "ê³¨ì ˆ/í™”ìƒ" (Fracture/Burn)

  Impact: 40-50 coverages across all carriers

  Note: Some may be legitimate short names; requires manual verification against source PDFs.

  Severity Ranking

  | Rank | Carrier | Issue Rate | Problem Type     | Resolution Difficulty               |
  |------|---------|------------|------------------|-------------------------------------|
  | 1    | KB      | 33%        | Numeric-only     | âš ï¸ Critical (PDF re-parsing needed) |
  | 2    | ë¡¯ë°      | 24.6%      | Category headers | âœ… Solvable (header detection logic) |
  | 3    | ë©”ë¦¬ì¸      | 22%        | Short names      | âš ï¸ Medium (headers + newlines)      |
  | 4    | ì‚¼ì„±      | 20.5%      | Time periods     | âš ï¸ Medium (special case handling)   |
  | 5    | í˜„ëŒ€      | 22%        | Generic terms    | âœ… Verification needed               |
  | 6    | í¥êµ­      | 26%        | Generic terms    | âœ… Verification needed               |
  | 7    | DB      | 27%        | Generic terms    | âœ… Verification needed               |
  | 8    | í•œí™”      | 7.8%       | Generic terms    | âœ… Verification needed               |

  Overall Impact Assessment

  Total Coverages: 357
  Definite Issues: 60-80 (17-22%)
  Needs Verification: 40-50 (11-14%)

  Total Affected: 100-130 / 357 = 28-36%

  By Carrier:

  | Carrier | Total | Short Names (â‰¤6 chars) | Percentage |
  |---------|-------|------------------------|------------|
  | ë©”ë¦¬ì¸      | 98    | 22                     | 22.4%      |
  | KB      | 36    | 19                     | 52.8%      |
  | ë¡¯ë°      | 57    | 14                     | 24.6%      |
  | ì‚¼ì„±      | 39    | 8                      | 20.5%      |
  | í¥êµ­      | 23    | 6                      | 26.1%      |
  | DB      | 22    | 6                      | 27.3%      |
  | í•œí™”      | 64    | 5                      | 7.8%       |
  | í˜„ëŒ€      | 18    | 4                      | 22.2%      |

  Impact on Phase 5 Evaluation

  Current Accuracy: 54% (27/50 queries)

  Failed Categories Most Affected by Coverage Issues:
  - Amount queries (16.7%): NL Mapper cannot match "ì•”ì§„ë‹¨" â†’ "ì•”ê´€ë ¨"
  - Comparison queries (50.0%): Ambiguous names prevent cross-carrier matching
  - Basic queries (90.0%): Less affected, still relies on vector search

  Estimated Accuracy After Fixes:
  - Fixing Lotte headers: +8-10% improvement
  - Fixing Meritz newlines: +2-3% improvement
  - Total expected: 64-67% (still short of 85-90% target)

  Resolution Strategy

  Priority 1: Immediate Fixes (This Iteration)

  1.1 Lotte Category Header Filter

  File: ingestion/parsers/table_parser.py

  def is_category_header(self, cells: List[str]) -> bool:
      """
      Detect category header rows (Lotte special case)
      
      Examples:
          ['ì•”ê´€ë ¨', 'ê°€ì…ê¸ˆì•¡: 3,000ë§Œì›']  â†’ True
          ['ì¼ë°˜ì•”ì§„ë‹¨ë¹„â…¡', '3,000ë§Œì›']  â†’ False
      """
      if not cells or not cells[0]:
          return False

      # Known category keywords (Lotte-specific)
      category_keywords = [
          'ì•”ê´€ë ¨', 'ë‡Œì§ˆí™˜', 'ì‹¬ì¥ì§ˆí™˜', 'ìˆ˜ìˆ ë¹„',
          'ê¸°ë³¸ê³„ì•½', 'ê³¨ì ˆ/í™”ìƒ', 'ê°±ì‹ ê³„ì•½'
      ]

      first_cell = cells[0].strip()

      # Pattern 1: Exact match with category keywords
      if first_cell in category_keywords:
          return True

      # Pattern 2: Very short generic terms (â‰¤4 chars with "ê´€ë ¨", "ì§ˆí™˜")
      if len(first_cell) <= 4 and any(kw in first_cell for kw in ['ê´€ë ¨', 'ì§ˆí™˜']):
          return True

      return False

  Integration: Call in parse_row() method before extracting coverage data.

  1.2 Meritz Newline Cleanup

  File: ingestion/coverage_pipeline.py or table_parser.py

  def clean_coverage_name(self, name: str) -> str:
      """Clean coverage name from parsing artifacts"""
      if not name:
          return name

      # Remove newlines and excessive whitespace
      cleaned = name.replace('\n', ' ').replace('\r', ' ')
      cleaned = ' '.join(cleaned.split())  # Normalize whitespace

      return cleaned

  1.3 Samsung Time Period Filter

  File: ingestion/parsers/table_parser.py

  def is_time_period_only(self, name: str) -> bool:
      """Detect time-period-only names (Samsung special case)"""
      import re

      # Pattern: "3ê°œì›”", "6ê°œì›”", "10ë…„"
      if re.match(r'^\d+(ê°œì›”|ë…„)$', name.strip()):
          return True

      return False

  1.4 KB Data Exclusion

  Status: Already excluded in current data
  Action: Keep excluded; revisit in Phase 6

  Priority 2: Medium-term Improvements

  2.1 Generic Name Validation

  - Manual review of "ì§ˆë³‘ì‚¬ë§", "ìƒí•´ìˆ˜ìˆ ë¹„" type names
  - Check against source PDF to determine if legitimate
  - Create whitelist of valid short names

  2.2 Context-aware Coverage Extraction

  - For ambiguous rows, check surrounding context
  - If previous row is category header, current row is likely sub-coverage
  - Concatenate header + row name: "ì•”ê´€ë ¨" + "ì¼ë°˜ì•”ì§„ë‹¨ë¹„" â†’ "ì¼ë°˜ì•”ì§„ë‹¨ë¹„"

  2.3 Enhanced Table Parser

  - Implement table structure analysis
  - Detect header rows, data rows, subtotal rows
  - Use font size, bold, indentation as hints

  Priority 3: Long-term Solutions

  3.1 KB PDF Re-processing

  - Investigate alternative PDF parsing libraries
  - Consider OCR if tables are image-based
  - Manual mapping as fallback

  3.2 Automated Coverage Validation

  - Build validation pipeline:
    a. Check length (too short = suspicious)
    b. Check for numbers only
    c. Check against known patterns
    d. Flag for manual review

  3.3 Coverage Quality Dashboard

  - UI for reviewing extracted coverages
  - Side-by-side: PDF original vs. extracted
  - Bulk edit/approve interface

  Recommended Execution Plan

  Phase A: Quick Wins (2-3 hours)

  1. âœ… Implement is_category_header() for Lotte
  2. âœ… Implement newline cleanup for Meritz
  3. âœ… Implement is_time_period_only() for Samsung
  4. ğŸ”„ Re-run Phase 1-4 for affected carriers

  Phase B: Verification (1-2 hours)

  1. Manual check of DB/í•œí™”/í˜„ëŒ€ generic names (sample 10-15)
  2. Update whitelist if legitimate
  3. Add additional filters if invalid

  Phase C: Re-evaluation (30 minutes)

  1. Run Phase 5 evaluation
  2. Measure accuracy improvement
  3. Document results in CHANGELOG.md

  Expected Outcomes

  After Phase A (Quick Wins):
  - Lotte: 14 invalid coverages â†’ 0
  - Meritz: 3-4 invalid coverages â†’ 0
  - Samsung: 4 invalid coverages â†’ 0
  - Total fixed: 21-22 coverages (5.9% of total)

  Expected Phase 5 Accuracy:
  - Current: 54%
  - After fixes: 68-72%
  - Still short of 85-90% target

  Additional work needed: NL Mapper improvements, age filtering (see original plan)

  Conclusion

  Coverage extraction quality issues are systemic across all carriers, not limited to DB/í˜„ëŒ€/í•œí™” row numbering problem identified earlier. While quick
   wins can address 20-25 coverages (5.9%), achieving 85-90% Phase 5 accuracy requires:

  1. âœ… Coverage extraction fixes (this report)
  2. â³ NL Mapper improvements (ambiguous name matching)
  3. â³ Age-based filtering implementation
  4. â³ KB data resolution or exclusion from QA set

  Recommendation: Proceed with Priority 1 fixes, measure improvement, then decide on Priority 2/3 based on results.

  ---