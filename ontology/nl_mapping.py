"""
Natural Language to Ontology Mapping

Maps natural language queries to structured ontology entities (Coverage, Product, Company, etc.)
Uses pattern matching and database lookups for entity extraction.

ì£¼ìš” ê¸°ëŠ¥:
- ì§ˆì˜ì—ì„œ ì—”í‹°í‹° ì¶”ì¶œ (ë‹´ë³´ëª…, ìƒí’ˆëª…, íšŒì‚¬ëª…, ì§ˆë³‘ëª… ë“±)
- DB ì¡°íšŒë¥¼ í†µí•œ ì •í™•í•œ ë§¤ì¹­
- ë§¤í•‘ëœ ì—”í‹°í‹°ë¥¼ í•„í„°ë¡œ ë³€í™˜í•˜ì—¬ ë²¡í„° ê²€ìƒ‰ì— í™œìš©

Usage:
    from ontology.nl_mapping import NLMapper

    mapper = NLMapper()
    entities = mapper.extract_entities("ì‚¼ì„±í™”ì¬ ë§ˆì´í—¬ìŠ¤ ì•”ì§„ë‹¨ê¸ˆì€?")
    # Returns: {
    #   "companies": ["ì‚¼ì„±í™”ì¬"],
    #   "products": ["ë§ˆì´í—¬ìŠ¤"],
    #   "coverages": ["ì•”ì§„ë‹¨ê¸ˆ"],
    #   "filters": {"company_id": 1, "product_id": 5}
    # }
"""

import re
import psycopg2
from typing import Dict, List, Any, Optional
import os


class NLMapper:
    """ìì—°ì–´ â†’ ì˜¨í†¨ë¡œì§€ ì—”í‹°í‹° ë§¤í•‘ í´ë˜ìŠ¤"""

    # íšŒì‚¬ëª… ë³„ì¹­ ë§¤í•‘ (alias â†’ DB company_name)
    COMPANY_ALIASES = {
        # ì‚¼ì„±
        'ì‚¼ì„±í™”ì¬': 'ì‚¼ì„±',
        'ì‚¼ì„±ìƒëª…': 'ì‚¼ì„±',
        'ì‚¼ì„±ì†ë³´': 'ì‚¼ì„±',
        'ì‚¼ì„±ì†í•´ë³´í—˜': 'ì‚¼ì„±',
        # DB (êµ¬ ë™ë¶€)
        'ë™ë¶€': 'DB',
        'ë™ë¶€í™”ì¬': 'DB',
        'ë™ë¶€ì†ë³´': 'DB',
        'ë™ë¶€ì†í•´ë³´í—˜': 'DB',
        'DBì†ë³´': 'DB',
        'DBì†í•´ë³´í—˜': 'DB',
        'DBí™”ì¬': 'DB',
        # í˜„ëŒ€
        'í˜„ëŒ€í•´ìƒ': 'í˜„ëŒ€',
        'í˜„ëŒ€ìƒëª…': 'í˜„ëŒ€',
        'í˜„ëŒ€ì†ë³´': 'í˜„ëŒ€',
        'í˜„ëŒ€ì†í•´ë³´í—˜': 'í˜„ëŒ€',
        # í•œí™”
        'í•œí™”ì†ë³´': 'í•œí™”',
        'í•œí™”ì†í•´ë³´í—˜': 'í•œí™”',
        'í•œí™”ìƒëª…': 'í•œí™”',
        'í•œí™”í™”ì¬': 'í•œí™”',
        # ë¡¯ë°
        'ë¡¯ë°ì†ë³´': 'ë¡¯ë°',
        'ë¡¯ë°ì†í•´ë³´í—˜': 'ë¡¯ë°',
        'ë¡¯ë°í™”ì¬': 'ë¡¯ë°',
        # KB
        'KBì†ë³´': 'KB',
        'KBì†í•´ë³´í—˜': 'KB',
        'KBìƒëª…': 'KB',
        # ë©”ë¦¬ì¸ 
        'ë©”ë¦¬ì¸ í™”ì¬': 'ë©”ë¦¬ì¸ ',
        'ë©”ë¦¬ì¸ ì†ë³´': 'ë©”ë¦¬ì¸ ',
        'ë©”ë¦¬ì¸ ì†í•´ë³´í—˜': 'ë©”ë¦¬ì¸ ',
        # í¥êµ­
        'í¥êµ­í™”ì¬': 'í¥êµ­',
        'í¥êµ­ìƒëª…': 'í¥êµ­',
        'í¥êµ­ì†ë³´': 'í¥êµ­',
    }

    def __init__(self, postgres_url: str = None):
        """
        Args:
            postgres_url: PostgreSQL ì—°ê²° ë¬¸ìì—´
        """
        self.postgres_url = postgres_url or os.getenv(
            "POSTGRES_URL",
            "postgresql://postgres:postgres@localhost:5432/insurance_ontology"
        )
        self.pg_conn = psycopg2.connect(self.postgres_url)

        # ì—”í‹°í‹° ìºì‹œ (ì„±ëŠ¥ ìµœì í™”)
        self._company_cache = None
        self._product_cache = None
        self._coverage_cache = None
        self._disease_cache = None

    def extract_entities(self, query: str) -> Dict[str, Any]:
        """
        ì§ˆì˜ì—ì„œ ì—”í‹°í‹° ì¶”ì¶œ

        Args:
            query: ìì—°ì–´ ì§ˆì˜

        Returns:
            ì¶”ì¶œëœ ì—”í‹°í‹°ì™€ í•„í„° ë”•ì…”ë„ˆë¦¬
        """
        entities = {
            "entities": {  # Add nested structure for compatibility
                "companies": [],
                "products": [],
                "coverages": [],
                "diseases": [],
            },
            "companies": [],
            "products": [],
            "coverages": [],
            "diseases": [],
            "keywords": [],
            "amount_filter": None,
            "gender_filter": None,
            "age_filter": None,
            "filters": {}
        }

        # 1. íšŒì‚¬ëª… ì¶”ì¶œ
        companies = self._extract_companies(query)
        if companies:
            entities["companies"] = companies
            entities["entities"]["companies"] = companies  # Also populate nested structure
            entities["filters"]["company_id"] = self._get_company_id(companies[0])

        # 2. ìƒí’ˆëª… ì¶”ì¶œ
        products = self._extract_products(query)
        if products:
            entities["products"] = products
            entities["filters"]["product_id"] = self._get_product_id(products[0])

        # 3. ë‹´ë³´ëª… ì¶”ì¶œ
        coverages = self._extract_coverages(query)
        if coverages:
            entities["coverages"] = coverages
            # Note: coverage_idëŠ” ë²¡í„° ê²€ìƒ‰ ë©”íƒ€ë°ì´í„° í•„í„°ë¡œ ì‚¬ìš© ê°€ëŠ¥
            coverage_ids = [self._get_coverage_id(c) for c in coverages]
            entities["filters"]["coverage_ids"] = [cid for cid in coverage_ids if cid]

        # 4. ì§ˆë³‘ëª… ì¶”ì¶œ
        diseases = self._extract_diseases(query)
        if diseases:
            entities["diseases"] = diseases

        # 5. ê¸ˆì•¡ í•„í„° ì¶”ì¶œ
        amount_filter = self._extract_amount(query)
        if amount_filter:
            entities["amount_filter"] = amount_filter
            entities["filters"]["amount"] = amount_filter

        # 6. ì„±ë³„ í•„í„° ì¶”ì¶œ
        gender_filter = self._extract_gender(query)
        if gender_filter:
            entities["gender_filter"] = gender_filter
            entities["filters"]["gender"] = gender_filter

        # 7. ë‚˜ì´ í•„í„° ì¶”ì¶œ
        age_filter = self._extract_age(query)
        if age_filter:
            entities["age_filter"] = age_filter
            entities["filters"]["age"] = age_filter

        # 8. í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ
        keywords = self._extract_keywords(query)
        entities["keywords"] = keywords

        return entities

    def _extract_companies(self, query: str) -> List[str]:
        """íšŒì‚¬ëª… ì¶”ì¶œ (ë³„ì¹­ ë§¤í•‘ + ë¶€ë¶„ ë§¤ì¹­ ì§€ì›)"""
        if not self._company_cache:
            self._load_company_cache()

        found = []
        found_set = set()  # ì¤‘ë³µ ë°©ì§€

        # 1. ë³„ì¹­ ë§¤í•‘ ìš°ì„  ì²˜ë¦¬ (ê¸´ ë³„ì¹­ë¶€í„° ë§¤ì¹­í•˜ì—¬ ì •í™•ë„ í–¥ìƒ)
        sorted_aliases = sorted(self.COMPANY_ALIASES.keys(), key=len, reverse=True)
        for alias in sorted_aliases:
            if alias in query:
                company_name = self.COMPANY_ALIASES[alias]
                if company_name not in found_set:
                    found.append(company_name)
                    found_set.add(company_name)

        # 2. DBì˜ íšŒì‚¬ëª…/ì½”ë“œ ì§ì ‘ ë§¤ì¹­
        for company in self._company_cache:
            company_name = company['company_name']
            company_code = company['company_code']

            if company_name in found_set:
                continue

            # ì „ì²´ ì´ë¦„ ì •í™• ë§¤ì¹­
            if company_name in query:
                found.append(company_name)
                found_set.add(company_name)
                continue

            # ì½”ë“œ ë§¤ì¹­ (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)
            if company_code and company_code.lower() in query.lower():
                found.append(company_name)
                found_set.add(company_name)
                continue

        # 3. í•µì‹¬ í‚¤ì›Œë“œ ë¶€ë¶„ ë§¤ì¹­ (ì˜ˆ: "ì‚¼ì„±" â†’ "ì‚¼ì„±")
        core_keywords = {
            'ì‚¼ì„±': 'ì‚¼ì„±',
            'ë™ë¶€': 'DB',  # ë™ë¶€ â†’ DB
            'DB': 'DB',
            'ë¡¯ë°': 'ë¡¯ë°',
            'ë©”ë¦¬ì¸ ': 'ë©”ë¦¬ì¸ ',
            'í•œí™”': 'í•œí™”',
            'í˜„ëŒ€': 'í˜„ëŒ€',
            'KB': 'KB',
            'í¥êµ­': 'í¥êµ­',
        }
        for keyword, company_name in core_keywords.items():
            if keyword in query and company_name not in found_set:
                found.append(company_name)
                found_set.add(company_name)

        return found

    def _extract_products(self, query: str) -> List[str]:
        """ìƒí’ˆëª… ì¶”ì¶œ"""
        if not self._product_cache:
            self._load_product_cache()

        found = []
        for product in self._product_cache:
            # ìƒí’ˆëª… ë¶€ë¶„ ë§¤ì¹­ (ì˜ˆ: "ë§ˆì´í—¬ìŠ¤", "ë¦¬ì–¼ì†ì†" ë“±)
            if product['name'] in query:
                found.append(product['name'])

        return found

    def _extract_coverages(self, query: str) -> List[str]:
        """ë‹´ë³´ëª… ì¶”ì¶œ (í‚¤ì›Œë“œ ê¸°ë°˜)"""
        if not self._coverage_cache:
            self._load_coverage_cache()

        query_normalized = query.replace(' ', '')
        found = []

        for coverage in self._coverage_cache:
            name = coverage['name']

            # ì •í™•í•œ ë§¤ì¹­
            if name in query:
                found.append(name)
                continue

            # ë¶€ë¶„ ë§¤ì¹­ (ì˜ˆ: "ì•” ì§„ë‹¨" â†’ "ì•”ì§„ë‹¨ë¹„")
            name_without_suffix = name.replace('ê¸ˆ', '').replace('ë¹„', '').replace('ë‹´ë³´', '')
            if name_without_suffix in query_normalized:
                found.append(name)
                continue

        # í‚¤ì›Œë“œ ê¸°ë°˜ ë§¤í•‘ (ì¼ë°˜ ìš©ì–´ â†’ í‘œì¤€ ë‹´ë³´ëª…)
        # ì •í™•í•œ ë§¤ì¹­ì´ ì—†ì„ ë•Œë§Œ í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰
        # if not found:  # ì œê±° - í•­ìƒ í‚¤ì›Œë“œ ê²€ìƒ‰ ìŠ¤í‚µí•˜ì—¬ ì¤‘ë³µ ë°©ì§€

        return list(set(found))  # ì¤‘ë³µ ì œê±°

    def _extract_diseases(self, query: str) -> List[str]:
        """ì§ˆë³‘ëª… ì¶”ì¶œ"""
        if not self._disease_cache:
            self._load_disease_cache()

        found = []
        for disease in self._disease_cache:
            if disease['name'] in query or disease['code'] in query:
                found.append(disease['name'])

        return found

    def _extract_keywords(self, query: str) -> List[str]:
        """í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ (ë³´í—˜ ë„ë©”ì¸ ìš©ì–´)"""
        # ë³´í—˜ ê´€ë ¨ í‚¤ì›Œë“œ íŒ¨í„´ (êµ¬ì²´ì  í‚¤ì›Œë“œë¥¼ ë¨¼ì € ë°°ì¹˜í•˜ì—¬ ìš°ì„  ë§¤ì¹­)
        # ìˆœì„œ: êµ¬ì²´ì  â†’ ì¼ë°˜ì  (ì œìë¦¬ì•” > ìœ ì‚¬ì•” > ì•”)
        insurance_keywords = [
            # êµ¬ì²´ì  ì•” ì¢…ë¥˜ (ìš°ì„ ìˆœìœ„ ë†’ìŒ)
            'ì œìë¦¬ì•”', 'ê²½ê³„ì„±ì¢…ì–‘', 'ìœ ì‚¬ì•”', '4ëŒ€ìœ ì‚¬ì•”',
            'ê°‘ìƒì„ ì•”', 'ê¸°íƒ€í”¼ë¶€ì•”', 'ì¬ì§„ë‹¨ì•”',
            'ì¼ë°˜ì•”', 'ì†Œì•¡ì•”', 'ê³ ì•¡ì•”',
            # ì¼ë°˜ ë³´ì¥ íƒ€ì…
            'ë³´ì¥', 'ì§„ë‹¨', 'ìˆ˜ìˆ ', 'ì…ì›', 'í†µì›',
            # ì¼ë°˜ ì•”/ì§ˆë³‘ (êµ¬ì²´ì  ì•” í‚¤ì›Œë“œ ì´í›„ì— ë§¤ì¹­)
            'ì•”', 'ë‡Œì¶œí˜ˆ', 'ê¸‰ì„±ì‹¬ê·¼ê²½ìƒ‰', 'ì§ˆë³‘', 'ìƒí•´',
            # ì¡°ê±´ ê´€ë ¨
            'ë©´ì±…', 'ê°ì•¡', 'ì§€ê¸‰', 'í•œë„', 'ì œí•œ',
            'ê°€ì…', 'ë‚˜ì´', 'ê¸°ê°„', 'ê¸ˆì•¡', 'ì¡°ê±´',
            # íŠ¹ìˆ˜ ë‹´ë³´
            'ë‹¤ë¹ˆì¹˜', 'ë¡œë´‡'
        ]

        found = []
        for keyword in insurance_keywords:
            if keyword in query:
                found.append(keyword)

        return found

    def _extract_amount(self, query: str) -> Optional[Dict[str, int]]:
        """
        ê¸ˆì•¡ í•„í„° ì¶”ì¶œ

        Examples:
            "3000ë§Œì›" â†’ {"min": 30000000, "max": 30000000}
            "2ì²œë§Œì› ì´ìƒ" â†’ {"min": 20000000, "max": None}
            "5000ë§Œì› ì´í•˜" â†’ {"min": None, "max": 50000000}
            "1ì–µ~2ì–µ" â†’ {"min": 100000000, "max": 200000000}

        Returns:
            {"min": int, "max": int} ë˜ëŠ” None
        """
        import re

        # íŒ¨í„´ 1: "Nì²œë§Œì›", "Nì–µì›", "Në§Œì›"
        patterns = [
            # "1ì–µ", "2ì–µ5ì²œë§Œì›" (ë¨¼ì € ì²˜ë¦¬)
            (r'(\d+)ì–µ(?:(\d+)ì²œ)?(?:(\d+)ë°±)?ë§Œ?ì›?', lambda m: (
                int(m.group(1)) * 100000000 +
                (int(m.group(2)) * 10000000 if m.group(2) else 0) +
                (int(m.group(3)) * 1000000 if m.group(3) else 0)
            )),
            # "3ì²œë§Œì›", "2ì²œ5ë°±ë§Œì›"
            (r'(\d+)ì²œ(?:(\d+)ë°±)?ë§Œì›', lambda m: (int(m.group(1)) * 1000 + (int(m.group(2)) * 100 if m.group(2) else 0)) * 10000),
            # "3000ë§Œì›", "3,000ë§Œì›" (ìˆœìˆ˜ ìˆ«ì+ë§Œì›)
            (r'(\d{1,4}),?(\d{3})ë§Œì›', lambda m: int(m.group(1) + m.group(2)) * 10000),
        ]

        amounts = []
        for pattern, converter in patterns:
            for match in re.finditer(pattern, query):
                try:
                    amount = converter(match)
                    amounts.append(amount)
                except:
                    pass

        if not amounts:
            return None

        # ë²”ìœ„ í‚¤ì›Œë“œ í™•ì¸
        if 'ì´ìƒ' in query:
            return {"min": min(amounts), "max": None}
        elif 'ì´í•˜' in query or 'ë¯¸ë§Œ' in query:
            return {"min": None, "max": max(amounts)}
        elif '~' in query or '-' in query or 'ì—ì„œ' in query:
            if len(amounts) >= 2:
                return {"min": min(amounts), "max": max(amounts)}
            else:
                return {"min": amounts[0], "max": amounts[0]}
        else:
            # ì •í™•í•œ ê¸ˆì•¡
            return {"min": amounts[0], "max": amounts[0]}

    def _extract_gender(self, query: str) -> Optional[str]:
        """
        ì„±ë³„ í•„í„° ì¶”ì¶œ

        Returns:
            "male", "female", ë˜ëŠ” None
        """
        if any(keyword in query for keyword in ['ë‚¨ì„±', 'ë‚¨ì', 'ë‚¨']):
            return 'male'
        elif any(keyword in query for keyword in ['ì—¬ì„±', 'ì—¬ì', 'ì—¬']):
            return 'female'
        return None

    def _extract_age(self, query: str) -> Optional[Dict[str, int]]:
        """
        ë‚˜ì´ í•„í„° ì¶”ì¶œ

        Examples:
            "40ì„¸" â†’ {"min": 40, "max": 40}
            "30ì„¸ ì´ìƒ" â†’ {"min": 30, "max": None}
            "50ì„¸ ì´í•˜" â†’ {"min": None, "max": 50}
            "20~30ì„¸" â†’ {"min": 20, "max": 30}

        Returns:
            {"min": int, "max": int} ë˜ëŠ” None
        """
        import re

        # ê¸ˆì•¡ ë‹¨ìœ„ê°€ ìˆìœ¼ë©´ ë‚˜ì´ ì¶”ì¶œ ê±´ë„ˆë›°ê¸°
        if any(keyword in query for keyword in ['ë§Œì›', 'ì–µ', 'ì²œë§Œ', 'ë°±ë§Œ']):
            # ëª…í™•í•œ ë‚˜ì´ í‘œí˜„ë§Œ ì¶”ì¶œ
            age_pattern = r'(\d{1,2})(?:ì„¸|ì‚´)'
        else:
            # ì¼ë°˜ íŒ¨í„´
            age_pattern = r'(\d{1,2})(?:ì„¸|ì‚´)?'

        matches = list(re.finditer(age_pattern, query))
        if not matches:
            return None

        ages = [int(m.group(1)) for m in matches if 1 <= int(m.group(1)) <= 120]  # í˜„ì‹¤ì ì¸ ë‚˜ì´ ë²”ìœ„

        if not ages:
            return None

        # ë²”ìœ„ í‚¤ì›Œë“œ í™•ì¸
        if 'ì´ìƒ' in query and 'ê°€ì…' in query:
            return {"min": min(ages), "max": None}
        elif ('ì´í•˜' in query or 'ë¯¸ë§Œ' in query) and 'ê°€ì…' in query:
            return {"min": None, "max": max(ages)}
        elif '~' in query or '-' in query:
            if len(ages) >= 2:
                return {"min": min(ages), "max": max(ages)}
        elif 'ì„¸' in query or 'ì‚´' in query or 'ê°€ì…' in query:
            # ëª…í™•í•œ ë‚˜ì´ ì»¨í…ìŠ¤íŠ¸
            return {"min": ages[0], "max": ages[0]}

        return None

    def _get_company_id(self, company_name: str) -> Optional[int]:
        """íšŒì‚¬ëª…ìœ¼ë¡œ company_id ì¡°íšŒ"""
        if not self._company_cache:
            self._load_company_cache()

        for company in self._company_cache:
            if company['company_name'] == company_name:  # Fixed: was 'name'
                return company['id']
        return None

    def _get_product_id(self, product_name: str) -> Optional[int]:
        """ìƒí’ˆëª…ìœ¼ë¡œ product_id ì¡°íšŒ"""
        if not self._product_cache:
            self._load_product_cache()

        for product in self._product_cache:
            if product['name'] == product_name:
                return product['id']
        return None

    def _get_coverage_id(self, coverage_name: str) -> Optional[int]:
        """ë‹´ë³´ëª…ìœ¼ë¡œ coverage_id ì¡°íšŒ"""
        if not self._coverage_cache:
            self._load_coverage_cache()

        for coverage in self._coverage_cache:
            if coverage['name'] == coverage_name:
                return coverage['id']
        return None

    def _load_company_cache(self):
        """íšŒì‚¬ ì •ë³´ ìºì‹œ ë¡œë“œ"""
        with self.pg_conn.cursor() as cur:
            cur.execute("SELECT id, company_name, company_code FROM company")
            self._company_cache = [
                {"id": row[0], "company_name": row[1], "company_code": row[2]}  # Fixed: match dict keys to usage
                for row in cur.fetchall()
            ]

    def _load_product_cache(self):
        """ìƒí’ˆ ì •ë³´ ìºì‹œ ë¡œë“œ"""
        with self.pg_conn.cursor() as cur:
            cur.execute("""
                SELECT p.id, p.product_name, p.business_type, c.company_name
                FROM product p
                JOIN company c ON p.company_id = c.id
            """)
            self._product_cache = [
                {
                    "id": row[0],
                    "name": row[1],
                    "product_type": row[2],
                    "company_name": row[3]
                }
                for row in cur.fetchall()
            ]

    def _load_coverage_cache(self):
        """ë‹´ë³´ ì •ë³´ ìºì‹œ ë¡œë“œ (coverage í…Œì´ë¸” + structured_data)"""
        with self.pg_conn.cursor() as cur:
            # 1. coverage í…Œì´ë¸”ì—ì„œ ê¸°ë³¸ ë‹´ë³´ ë¡œë“œ
            cur.execute("""
                SELECT DISTINCT c.id, c.coverage_name, c.coverage_category
                FROM coverage c
                ORDER BY c.coverage_name
            """)
            self._coverage_cache = [
                {"id": row[0], "name": row[1], "coverage_group": row[2]}
                for row in cur.fetchall()
            ]

            # 2. clause_embedding.metadata->structured_dataì—ì„œ ì¶”ê°€ ë‹´ë³´ëª… ë¡œë“œ
            cur.execute("""
                SELECT DISTINCT
                    ce.metadata->'structured_data'->>'coverage_name' as coverage_name
                FROM clause_embedding ce
                WHERE ce.metadata->'structured_data'->>'coverage_name' IS NOT NULL
                  AND ce.metadata->'structured_data'->>'coverage_name' != ''
            """)

            # ê¸°ì¡´ ë‹´ë³´ëª… set ìƒì„± (ì¤‘ë³µ ë°©ì§€)
            existing_names = {c['name'] for c in self._coverage_cache}

            # structured_dataì˜ ë‹´ë³´ëª… ì¶”ê°€ (ì¤‘ë³µ ì œì™¸)
            for row in cur.fetchall():
                coverage_name = row[0]
                if coverage_name and coverage_name not in existing_names:
                    # IDëŠ” None (coverage í…Œì´ë¸”ì— ì—†ëŠ” ë‹´ë³´)
                    self._coverage_cache.append({
                        "id": None,
                        "name": coverage_name,
                        "coverage_group": "ê¸°íƒ€"
                    })
                    existing_names.add(coverage_name)

    def _load_disease_cache(self):
        """ì§ˆë³‘ ì½”ë“œ ì •ë³´ ìºì‹œ ë¡œë“œ"""
        with self.pg_conn.cursor() as cur:
            cur.execute("""
                SELECT DISTINCT dc.code, dc.description_kr
                FROM disease_code dc
                LIMIT 1000  -- ì„±ëŠ¥ì„ ìœ„í•´ ì œí•œ
            """)
            self._disease_cache = [
                {"code": row[0], "name": row[1] or row[0]}
                for row in cur.fetchall()
            ]

    def get_filtered_search_params(
        self,
        query: str,
        base_limit: int = 10
    ) -> Dict[str, Any]:
        """
        ì§ˆì˜ë¥¼ íŒŒì‹±í•˜ì—¬ ë²¡í„° ê²€ìƒ‰ íŒŒë¼ë¯¸í„° ìƒì„±

        Args:
            query: ìì—°ì–´ ì§ˆì˜
            base_limit: ê¸°ë³¸ ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜

        Returns:
            ê²€ìƒ‰ íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬
        """
        entities = self.extract_entities(query)

        params = {
            "query": query,
            "top_k": base_limit,
            "company_id": entities["filters"].get("company_id"),
            "product_id": entities["filters"].get("product_id"),
            "doc_type": None  # í•„ìš”ì‹œ ì¶”ê°€
        }

        return params

    def explain_entities(self, query: str) -> str:
        """
        ì¶”ì¶œëœ ì—”í‹°í‹°ë¥¼ ì‚¬ëŒì´ ì½ì„ ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ì„¤ëª…

        Args:
            query: ìì—°ì–´ ì§ˆì˜

        Returns:
            ì—”í‹°í‹° ì„¤ëª… í…ìŠ¤íŠ¸
        """
        entities = self.extract_entities(query)

        lines = [f"Query: {query}", ""]

        if entities["companies"]:
            lines.append(f"ğŸ¢ Companies: {', '.join(entities['companies'])}")

        if entities["products"]:
            lines.append(f"ğŸ“¦ Products: {', '.join(entities['products'])}")

        if entities["coverages"]:
            lines.append(f"ğŸ›¡ï¸ Coverages: {', '.join(entities['coverages'])}")

        if entities["diseases"]:
            lines.append(f"ğŸ¥ Diseases: {', '.join(entities['diseases'])}")

        if entities["amount_filter"]:
            amt = entities["amount_filter"]
            if amt["min"] and amt["max"]:
                if amt["min"] == amt["max"]:
                    lines.append(f"ğŸ’° Amount: {amt['min']:,}ì›")
                else:
                    lines.append(f"ğŸ’° Amount: {amt['min']:,}ì› ~ {amt['max']:,}ì›")
            elif amt["min"]:
                lines.append(f"ğŸ’° Amount: â‰¥ {amt['min']:,}ì›")
            elif amt["max"]:
                lines.append(f"ğŸ’° Amount: â‰¤ {amt['max']:,}ì›")

        if entities["gender_filter"]:
            lines.append(f"ğŸ‘¤ Gender: {entities['gender_filter']}")

        if entities["age_filter"]:
            age = entities["age_filter"]
            if age["min"] and age["max"]:
                if age["min"] == age["max"]:
                    lines.append(f"ğŸ‚ Age: {age['min']}ì„¸")
                else:
                    lines.append(f"ğŸ‚ Age: {age['min']}ì„¸ ~ {age['max']}ì„¸")
            elif age["min"]:
                lines.append(f"ğŸ‚ Age: â‰¥ {age['min']}ì„¸")
            elif age["max"]:
                lines.append(f"ğŸ‚ Age: â‰¤ {age['max']}ì„¸")

        if entities["keywords"]:
            lines.append(f"ğŸ”‘ Keywords: {', '.join(entities['keywords'])}")

        if entities["filters"]:
            lines.append(f"\nğŸ“Œ Filters: {entities['filters']}")

        return "\n".join(lines)

    def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        if self.pg_conn:
            self.pg_conn.close()

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.close()


# í¸ì˜ í•¨ìˆ˜
def extract_entities_from_query(query: str, postgres_url: str = None) -> Dict[str, Any]:
    """
    ì§ˆì˜ì—ì„œ ì—”í‹°í‹° ì¶”ì¶œ (ì›ìƒ· í•¨ìˆ˜)

    Args:
        query: ìì—°ì–´ ì§ˆì˜
        postgres_url: PostgreSQL ì—°ê²° ë¬¸ìì—´

    Returns:
        ì¶”ì¶œëœ ì—”í‹°í‹° ë”•ì…”ë„ˆë¦¬
    """
    with NLMapper(postgres_url) as mapper:
        return mapper.extract_entities(query)
