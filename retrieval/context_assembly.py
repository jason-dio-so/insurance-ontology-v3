"""
Context Assembly

ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ì™€ DB êµ¬ì¡°í™” ë°ì´í„°ë¥¼ ë³‘í•©í•˜ì—¬ LLMì— ì „ë‹¬í•  ì»¨í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ + DB êµ¬ì¡°í™” ë°ì´í„° ë³‘í•©
- ì¤‘ë³µ ì œê±° ë° ë­í‚¹
- Citation ë§¤í•‘ (clause_id, document_id, page)
- LLM í”„ë¡¬í”„íŠ¸ìš© í¬ë§·íŒ…

Usage:
    from retrieval.context_assembly import ContextAssembler

    assembler = ContextAssembler()
    context = assembler.assemble(
        vector_results=retriever_results,
        query="ì•” ì§„ë‹¨ì‹œ ë³´ì¥ê¸ˆì•¡ì€?"
    )
"""

import os
import psycopg2
from typing import List, Dict, Any, Optional
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()


class ContextAssembler:
    """ì»¨í…ìŠ¤íŠ¸ ì¡°ë¦½ í´ë˜ìŠ¤"""

    def __init__(self, postgres_url: str = None):
        """
        Args:
            postgres_url: PostgreSQL ì—°ê²° ë¬¸ìì—´
        """
        self.postgres_url = postgres_url or os.getenv("POSTGRES_URL")
        if not self.postgres_url:
            raise ValueError("POSTGRES_URL environment variable is required. Check .env file.")
        self.pg_conn = psycopg2.connect(self.postgres_url)

    def assemble(
        self,
        vector_results: List[Dict[str, Any]],
        query: str,
        max_context_length: int = 4000,
        include_metadata: bool = True
    ) -> Dict[str, Any]:
        """
        ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ë¥¼ LLMìš© ì»¨í…ìŠ¤íŠ¸ë¡œ ì¡°ë¦½í•©ë‹ˆë‹¤.

        Args:
            vector_results: ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
            query: ì‚¬ìš©ì ì§ˆì˜
            max_context_length: ìµœëŒ€ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ (í† í° ìˆ˜)
            include_metadata: ë©”íƒ€ë°ì´í„° í¬í•¨ ì—¬ë¶€

        Returns:
            ì¡°ë¦½ëœ ì»¨í…ìŠ¤íŠ¸ ë”•ì…”ë„ˆë¦¬
            {
                "query": str,
                "context_text": str,  # LLMì— ì „ë‹¬í•  í…ìŠ¤íŠ¸
                "clauses": List[Dict],  # ì¡°í•­ ì •ë³´
                "citations": List[Dict],  # ì¸ìš© ì •ë³´
                "metadata": Dict  # ì¶”ê°€ ë©”íƒ€ë°ì´í„°
            }
        """
        # 1. ì¤‘ë³µ ì œê±°
        unique_results = self._deduplicate(vector_results)

        # 2. ë­í‚¹ (ì´ë¯¸ ìœ ì‚¬ë„ìˆœìœ¼ë¡œ ì •ë ¬ë˜ì–´ ìˆìŒ)
        ranked_results = self._rank(unique_results)

        # 3. DBì—ì„œ ì¶”ê°€ ë©”íƒ€ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        enriched_results = self._enrich_with_metadata(ranked_results)

        # 4. Citation ë§¤í•‘
        citations = self._build_citations(enriched_results)

        # 5. ì»¨í…ìŠ¤íŠ¸ í…ìŠ¤íŠ¸ ìƒì„±
        context_text = self._build_context_text(
            enriched_results,
            max_length=max_context_length
        )

        # 6. ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘
        metadata = self._collect_metadata(enriched_results) if include_metadata else {}

        return {
            "query": query,
            "context_text": context_text,
            "clauses": enriched_results,
            "citations": citations,
            "metadata": metadata
        }

    def _deduplicate(self, results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        ì¤‘ë³µ ì¡°í•­ ì œê±°

        Args:
            results: ê²€ìƒ‰ ê²°ê³¼

        Returns:
            ì¤‘ë³µ ì œê±°ëœ ê²°ê³¼
        """
        seen_clause_ids = set()
        unique_results = []

        for result in results:
            clause_id = result.get('clause_id')
            if clause_id not in seen_clause_ids:
                seen_clause_ids.add(clause_id)
                unique_results.append(result)

        return unique_results

    def _rank(self, results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        ê²°ê³¼ ë­í‚¹ (ìœ ì‚¬ë„ + ë¬¸ì„œ íƒ€ì… ê°€ì¤‘ì¹˜)

        Args:
            results: ê²€ìƒ‰ ê²°ê³¼

        Returns:
            ë­í‚¹ëœ ê²°ê³¼
        """
        # ë¬¸ì„œ íƒ€ì…ë³„ ê°€ì¤‘ì¹˜ (ê°€ì…ì„¤ê³„ì„œ > ìƒí’ˆìš”ì•½ì„œ > ì‚¬ì—…ë°©ë²•ì„œ > ì•½ê´€)
        doc_type_weights = {
            'ê°€ì…ì„¤ê³„ì„œ': 1.2,    # êµ¬ì²´ì ì¸ ë³´ì¥ê¸ˆì•¡, ë³´í—˜ë£Œ ì •ë³´
            'proposal': 1.2,
            'ìƒí’ˆìš”ì•½ì„œ': 1.15,   # ìš”ì•½ëœ ë³´ì¥ ì •ë³´
            'product_summary': 1.15,
            'ì‚¬ì—…ë°©ë²•ì„œ': 1.1,    # ê°€ì… ì¡°ê±´, ì œì•½ì‚¬í•­
            'business_spec': 1.1,
            'ì•½ê´€': 1.0,          # ì¼ë°˜ ì¡°í•­
            'terms': 1.0
        }

        # ì¬ìŠ¤ì½”ì–´ë§ ë° ì •ë ¬
        for result in results:
            original_similarity = result.get('similarity', 0)
            doc_type = result.get('doc_type', 'ì•½ê´€')
            weight = doc_type_weights.get(doc_type, 1.0)

            # ê°€ì¤‘ì¹˜ ì ìš©í•œ ìŠ¤ì½”ì–´ ê³„ì‚°
            result['weighted_score'] = original_similarity * weight
            result['doc_type_weight'] = weight

        # weighted_score ê¸°ì¤€ìœ¼ë¡œ ì¬ì •ë ¬
        ranked = sorted(results, key=lambda x: x.get('weighted_score', 0), reverse=True)

        return ranked

    def _enrich_with_metadata(
        self,
        results: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """
        DBì—ì„œ ì¶”ê°€ ë©”íƒ€ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ì„œ ê²°ê³¼ë¥¼ í’ë¶€í•˜ê²Œ ë§Œë“­ë‹ˆë‹¤.

        Args:
            results: ê²€ìƒ‰ ê²°ê³¼

        Returns:
            ë©”íƒ€ë°ì´í„°ê°€ ì¶”ê°€ëœ ê²°ê³¼
        """
        if not results:
            return results

        clause_ids = [r['clause_id'] for r in results]

        with self.pg_conn.cursor() as cur:
            # ì¡°í•­ ìƒì„¸ ì •ë³´ + ë¬¸ì„œ ì •ë³´ ì¡°íšŒ
            cur.execute("""
                SELECT
                    dc.id as clause_id,
                    dc.clause_number,
                    dc.clause_title,
                    dc.section_type,
                    dc.page_number,
                    doc.document_id,
                    doc.doc_type,
                    doc.doc_subtype,
                    c.company_name as company_name,
                    c.company_code as company_code,
                    p.product_name as product_name,
                    p.business_type
                FROM document_clause dc
                JOIN document doc ON dc.document_id = doc.id
                LEFT JOIN company c ON doc.company_id = c.id
                LEFT JOIN product p ON doc.product_id = p.id
                WHERE dc.id = ANY(%s)
            """, (clause_ids,))

            metadata_map = {}
            for row in cur.fetchall():
                metadata_map[row[0]] = {
                    'clause_number': row[1],
                    'clause_title': row[2],
                    'section_type': row[3],
                    'page_number': row[4],
                    'document_id': row[5],
                    'doc_type': row[6],
                    'doc_subtype': row[7],
                    'company_name': row[8],
                    'company_code': row[9],
                    'product_name': row[10],
                    'product_type': row[11]
                }

            # âœ¨ Context Enrichment: Add coverage/benefit information
            cur.execute("""
                SELECT
                    dc.id as clause_id,
                    c.coverage_name,
                    c.id as coverage_id,
                    b.benefit_amount,
                    b.benefit_type,
                    b.payment_frequency
                FROM document_clause dc
                LEFT JOIN clause_coverage cc ON dc.id = cc.clause_id
                LEFT JOIN coverage c ON cc.coverage_id = c.id
                LEFT JOIN benefit b ON c.id = b.coverage_id
                WHERE dc.id = ANY(%s)
                  AND c.coverage_name IS NOT NULL
            """, (clause_ids,))

            # Store coverage/benefit info (can have multiple per clause)
            coverage_map = {}
            for row in cur.fetchall():
                clause_id = row[0]
                if clause_id not in coverage_map:
                    coverage_map[clause_id] = []

                coverage_info = {
                    'coverage_name': row[1],
                    'coverage_id': row[2],
                    'benefit_amount': row[3],
                    'benefit_type': row[4],
                    'payment_frequency': row[5]
                }
                coverage_map[clause_id].append(coverage_info)

        # ê²°ê³¼ì— ë©”íƒ€ë°ì´í„° ë³‘í•©
        enriched = []
        for result in results:
            clause_id = result['clause_id']
            if clause_id in metadata_map:
                enriched_result = {**result, **metadata_map[clause_id]}

                # Add coverage/benefit info if available
                if clause_id in coverage_map:
                    enriched_result['coverages'] = coverage_map[clause_id]

                enriched.append(enriched_result)
            else:
                # Even if no metadata, add coverage info if available
                enriched_result = {**result}
                if clause_id in coverage_map:
                    enriched_result['coverages'] = coverage_map[clause_id]
                enriched.append(enriched_result)

        return enriched

    def _build_citations(
        self,
        results: List[Dict[str, Any]]
    ) -> List[Dict[str, str]]:
        """
        Citation ì •ë³´ ìƒì„±

        Args:
            results: ê²€ìƒ‰ ê²°ê³¼

        Returns:
            Citation ë¦¬ìŠ¤íŠ¸
        """
        citations = []
        for i, result in enumerate(results, 1):
            citation = {
                'index': i,
                'clause_id': result.get('clause_id'),
                'clause_number': result.get('clause_number', 'N/A'),
                'clause_title': result.get('clause_title', ''),
                'document_id': result.get('document_id', 'N/A'),
                'doc_type': result.get('doc_type', 'N/A'),
                'page_number': result.get('page_number'),
                'company_name': result.get('company_name', 'N/A'),
                'product_name': result.get('product_name', 'N/A')
            }
            citations.append(citation)

        return citations

    def _build_context_text(
        self,
        results: List[Dict[str, Any]],
        max_length: int = 4000
    ) -> str:
        """
        LLMì— ì „ë‹¬í•  ì»¨í…ìŠ¤íŠ¸ í…ìŠ¤íŠ¸ ìƒì„±

        Args:
            results: ê²€ìƒ‰ ê²°ê³¼
            max_length: ìµœëŒ€ ê¸¸ì´ (ëŒ€ëµì ì¸ ë¬¸ì ìˆ˜)

        Returns:
            ì»¨í…ìŠ¤íŠ¸ í…ìŠ¤íŠ¸
        """
        context_parts = []
        current_length = 0

        for i, result in enumerate(results, 1):
            # Citation í—¤ë”
            citation_header = f"[{i}] {result.get('clause_number', 'N/A')}"
            if result.get('clause_title'):
                citation_header += f" {result['clause_title']}"
            citation_header += f"\nì¶œì²˜: {result.get('doc_type', 'N/A')}"
            if result.get('company_name'):
                citation_header += f" ({result['company_name']})"
            if result.get('page_number'):
                citation_header += f" - í˜ì´ì§€ {result['page_number']}"

            # ì¡°í•­ ë‚´ìš©
            clause_text = result.get('clause_text', '')

            # âœ¨ Coverage/Benefit ì •ë³´ ì¶”ê°€ (Phase 5 v5: Enhanced amount formatting)
            coverage_text = ""
            if 'coverages' in result and result['coverages']:
                coverage_text = "\nğŸ“‹ ë³´ì¥ ì •ë³´:\n"
                for cov in result['coverages']:
                    coverage_text += f"  - ë‹´ë³´ëª…: {cov.get('coverage_name', 'N/A')}\n"
                    if cov.get('benefit_amount'):
                        # Format amount in both numeric and Korean formats
                        # Phase 5 v5: Prioritize numeric format for better LLM extraction
                        amount = float(cov['benefit_amount'])

                        # Numeric format with commas (e.g., "1,000ë§Œì›", "5,000ë§Œì›")
                        if amount >= 100000000:  # 1ì–µ ì´ìƒ
                            man_units = int(amount / 10000)  # Convert to ë§Œì›
                            amount_numeric = f"{man_units:,}ë§Œì›"  # With commas
                            amount_kr = f"{amount/100000000:.0f}ì–µì›"
                        elif amount >= 10000:  # 1ë§Œ ì´ìƒ
                            man_units = int(amount / 10000)
                            amount_numeric = f"{man_units:,}ë§Œì›"  # e.g., "1,000ë§Œì›"
                            amount_kr = f"{amount/10000:.0f}ë§Œì›"  # e.g., "1000ë§Œì›"
                        else:
                            amount_numeric = f"{amount:,.0f}ì›"
                            amount_kr = f"{amount:.0f}ì›"

                        # Highlight numeric format, show Korean format in parentheses
                        coverage_text += f"    ğŸ’° ë³´ì¥ê¸ˆì•¡: **{amount_numeric}** ({amount_kr})\n"
                    if cov.get('benefit_type'):
                        type_kr = {
                            'diagnosis': 'ì§„ë‹¨',
                            'surgery': 'ìˆ˜ìˆ ',
                            'hospitalization': 'ì…ì›',
                            'treatment': 'ì¹˜ë£Œ',
                            'death': 'ì‚¬ë§',
                            'other': 'ê¸°íƒ€'
                        }.get(cov['benefit_type'], cov['benefit_type'])
                        coverage_text += f"    ë³´ì¥ìœ í˜•: {type_kr}\n"

            # ì „ì²´ í•­ëª©
            item = f"{citation_header}\n{clause_text}{coverage_text}\n\n"

            # ê¸¸ì´ ì²´í¬
            if current_length + len(item) > max_length:
                break

            context_parts.append(item)
            current_length += len(item)

        return "".join(context_parts)

    def _collect_metadata(
        self,
        results: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        ì¶”ê°€ ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘

        Args:
            results: ê²€ìƒ‰ ê²°ê³¼

        Returns:
            ë©”íƒ€ë°ì´í„° ë”•ì…”ë„ˆë¦¬
        """
        if not results:
            return {}

        # íšŒì‚¬ ë° ìƒí’ˆ ì •ë³´ ìˆ˜ì§‘
        companies = set()
        products = set()
        doc_types = set()

        for result in results:
            if result.get('company_name'):
                companies.add(result['company_name'])
            if result.get('product_name'):
                products.add(result['product_name'])
            if result.get('doc_type'):
                doc_types.add(result['doc_type'])

        return {
            'num_clauses': len(results),
            'companies': list(companies),
            'products': list(products),
            'doc_types': list(doc_types),
            'avg_similarity': sum(r.get('similarity', 0) for r in results) / len(results) if results else 0
        }

    def close(self):
        """PostgreSQL ì—°ê²° ì¢…ë£Œ"""
        if self.pg_conn:
            self.pg_conn.close()

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.close()
